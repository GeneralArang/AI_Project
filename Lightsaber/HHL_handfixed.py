# -*- coding: utf-8 -*-
import cv2
import time
import math
import numpy as np
import mediapipe as mp
from dataclasses import dataclass
from typing import List, Tuple
from openvino.runtime import Core, CompiledModel

# =========================
# ì„¤ì •
# =========================
MODEL_XML = "/home/dx08/workspace/open_model_zoo/demos/human_pose_estimation_demo/python/intel/human-pose-estimation-0005/FP32/human-pose-estimation-0005.xml"
DEVICE = "AUTO"          # "CPU", "GPU", "AUTO" ë“±
CAM_INDEX = 4           # ì¹´ë©”ë¼ ì¸ë±ìŠ¤

CONF_KPT = 0.2           # ì „ì‹  í‚¤í¬ì¸íŠ¸ í‘œì‹œ ì„ê³„ê°’
CONF_WRIST = 0.3         # ì†ëª© ë°•ìŠ¤ ìƒì„± ì„ê³„ê°’
MAX_HANDS = 4            # MediaPipe ìµœëŒ€ ì† ìˆ˜

# ë¯¸ëŸ¬(ì…€í”¼) í”„ë¦¬ë·° ë³´ì •: í™”ë©´ì´ ì¢Œìš°ë°˜ì „ë˜ì–´ ë³´ì¼ ë•Œ True
MIRROR = True

# ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ê¸°ì¤€ ì†ëª© ì¸ë±ìŠ¤(ì§ˆë¬¸ ë‚´ìš© ë°˜ì˜: Left=10, Right=9)
BODY_WRIST_IDX = {'Left': 10, 'Right': 9}

# (ì„ íƒ) ì–´ê¹¨ ì¸ë±ìŠ¤: ëª¸ ì¤‘ì‹¬ì„  íŒíŠ¸ìš©(ëª¨ë¸ì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥)
BODY_SHOULDER_IDX = {'Left': 5, 'Right': 2}

# =========================
# ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²°(ìš”ì²­í•œ ìˆœì„œë¡œ ê³ ì •)
# =========================
POSE_PAIRS = (
    (15, 13), (13, 11), (16, 14), (14, 12), (11, 12), (5, 11), (6, 12), (5, 6),
    (5, 7), (6, 8), (7, 9), (8, 10), (1, 2), (0, 1), (0, 2), (1, 3), (2, 4), (3, 5), (4, 6)
)

# =========================
# ìœ í‹¸
# =========================
@dataclass
class Keypoint:
    x: float
    y: float
    conf: float

Keypoints = List[Keypoint]


# --------- í¬ë¡œë§ˆí‚¤(ê²€ì€ ë°°ê²½ íˆ¬ëª…í™”) ----------
def make_black_transparent(img_rgba, thr=30, soft_edge=5):
    """
    img_rgba: (H,W,3|4) BGR(A)
    thr: íšŒìƒ‰ê°’ <= thr ì¸ ì–´ë‘ìš´(ê²€ì€) ì˜ì—­ì„ íˆ¬ëª… ì²˜ë¦¬
    soft_edge>0: ê²½ê³„ í˜ë”ë§
    """
    assert img_rgba.shape[2] in (3, 4)
    if img_rgba.shape[2] == 3:
        a = np.full(img_rgba.shape[:2] + (1,), 255, np.uint8)
        img_rgba = np.concatenate([img_rgba, a], axis=2)

    bgr = img_rgba[..., :3]
    alpha = img_rgba[..., 3].copy()
    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)

    black_mask = (gray <= thr).astype(np.uint8) * 255  # ê²€ì€ ì˜ì—­(íˆ¬ëª…ìœ¼ë¡œ ë§Œë“¤ ëŒ€ìƒ)
    if soft_edge > 0:
        inv = 255 - black_mask
        dist = cv2.distanceTransform(inv, cv2.DIST_L2, 3)
        dist = np.clip(dist / float(soft_edge), 0.0, 1.0)
        feather = (dist * 255).astype(np.uint8)  # ê²€ì€ ì˜ì—­ ì£¼ë³€ì„ ë¶€ë“œëŸ½ê²Œ 0â†’255
        new_alpha = np.minimum(alpha, feather)   # ê²½ê³„ìª½ íˆ¬ëª…ë„ ì„œì„œíˆ ì¦ê°€
    else:
        new_alpha = alpha
        new_alpha[black_mask == 255] = 0

    out = img_rgba.copy()
    out[..., 3] = new_alpha
    return out

# ---------------------------------------------

# --------- ìë™ íŠ¸ë¦¬ë°(ì•ŒíŒŒ ì±„ë„ ê¸°ì¤€) ----------
def trim_transparent_area(img_rgba):
    """ì•ŒíŒŒ ì±„ë„ì´ 0ì´ ì•„ë‹Œ ë¶€ë¶„ë§Œ ì˜ë¼ë‚´ê¸° (ìë™ íŠ¸ë¦¬ë°)"""
    if img_rgba is None or img_rgba.shape[2] < 4:
        return img_rgba
    alpha = img_rgba[..., 3]
    ys, xs = np.where(alpha > 10)
    if len(ys) == 0 or len(xs) == 0:
        return img_rgba
    y1, y2 = ys.min(), ys.max()
    x1, x2 = xs.min(), xs.max()
    return img_rgba[y1:y2+1, x1:x2+1]


def clamp_box(x1, y1, x2, y2, w, h):
    return max(0, x1), max(0, y1), min(w-1, x2), min(h-1, y2)

# =========================
# ì „ì‹  í¬ì¦ˆ ì¶”ì • ëª¨ë“ˆ(OpenVINO)
# =========================
class OpenVinoPose:
    def __init__(self, model_xml: str, device: str = "AUTO"):
        ie = Core()
        model = ie.read_model(model_xml)
        self.compiled: CompiledModel = ie.compile_model(model, device)
        self.input_port = self.compiled.input(0)
        self.output_port = self.compiled.output(0)
        _, _, self.in_h, self.in_w = self.input_port.shape
        print(f"[Pose] Input expects: {self.in_h}x{self.in_w}")

    def preprocess(self, frame: np.ndarray) -> np.ndarray:
        img_resized = cv2.resize(frame, (self.in_w, self.in_h))
        img_input = img_resized.transpose(2, 0, 1)[np.newaxis, :].astype(np.float32)
        return img_input

    def infer(self, frame: np.ndarray) -> np.ndarray:
        inp = self.preprocess(frame)
        res = self.compiled({self.input_port: inp})[self.output_port]
        return np.asarray(res)

    def extract_keypoints(self, output: np.ndarray, orig_w: int, orig_h: int) -> Keypoints:
        out = output.squeeze(0) if output.ndim == 4 else output  # [C,H,W]
        C, Hh, Wh = out.shape
        max_k = min(18, C)  # 0~17 ê´€ì ˆë§Œ ì‚¬ìš©
        kpts: Keypoints = []
        for i in range(max_k):
            hm = out[i]
            _, conf, _, point = cv2.minMaxLoc(hm)
            x_hm, y_hm = point
            x = int(x_hm * orig_w / Wh)
            y = int(y_hm * orig_h / Hh)
            kpts.append(Keypoint(x, y, float(conf)))
        return kpts

# =========================
# ì† ì¶”ì •(ë¯¸ë””ì–´íŒŒì´í”„) ëª¨ë“ˆ
# =========================
class MediaPipeHands:
    def __init__(self, max_hands: int = 2):
        self.mp_hands = mp.solutions.hands
        self.mp_drawing = mp.solutions.drawing_utils
        self.hands = self.mp_hands.Hands(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5,
            max_num_hands=max_hands
        )
    def process(self, frame_bgr: np.ndarray):
        rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        return self.hands.process(rgb)
    def draw(self, frame_bgr: np.ndarray, results):
        if not results.multi_hand_landmarks:
            return []
        drawn = []
        for hand_lm, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):
            label = handedness.classification[0].label  # "Left" or "Right"
            color = (0,255,0) if label == "Left" else (255,0,0)
            self.mp_drawing.draw_landmarks(
                frame_bgr, hand_lm, self.mp_hands.HAND_CONNECTIONS,
                self.mp_drawing.DrawingSpec(thickness=2, circle_radius=2),
                self.mp_drawing.DrawingSpec(thickness=2)
            )
            drawn.append((label, handedness.classification[0].score, hand_lm))
        return drawn

# =========================
# ì‹œê°í™”(ìŠ¤ì¼ˆë ˆí†¤ & ì†-ì†ëª© ì—°ê²°)
# =========================
class Visualizer:
    def __init__(self, pose_pairs=POSE_PAIRS, conf_thr=CONF_KPT):
        self.pose_pairs = pose_pairs
        self.conf_thr = conf_thr

    def draw_keypoints(self, img: np.ndarray, kpts: Keypoints, color=(0,255,0)):
        for kp in kpts:
            if kp.conf > self.conf_thr:
                cv2.circle(img, (int(kp.x), int(kp.y)), 3, color, -1)

    def draw_skeleton(self, img: np.ndarray, kpts: Keypoints, color=(0,255,0)):
        self.draw_keypoints(img, kpts, color)
        for a, b in self.pose_pairs:
            if a < len(kpts) and b < len(kpts):
                ka, kb = kpts[a], kpts[b]
                if ka.conf > self.conf_thr and kb.conf > self.conf_thr:
                    cv2.line(img, (int(ka.x), int(ka.y)), (int(kb.x), int(kb.y)), color, 2)

    def draw_hand_labels_and_attach(self, img: np.ndarray, hands_drawn, img_w, img_h, body_kpts: Keypoints):
        if not body_kpts:
            return
        # ì „ì‹  ì†ëª© ì¢Œí‘œ ìˆ˜ì§‘
        wrists = {}
        for side, idx in BODY_WRIST_IDX.items():
            if idx < len(body_kpts) and body_kpts[idx].conf > self.conf_thr:
                wrists[side] = (int(body_kpts[idx].x), int(body_kpts[idx].y))

        # ëª¸ ì¤‘ì‹¬ì„ (ì–´ê¹¨ í‰ê·  x)
        mid_x = None
        ls, rs = BODY_SHOULDER_IDX['Left'], BODY_SHOULDER_IDX['Right']
        if ls < len(body_kpts) and rs < len(body_kpts):
            if body_kpts[ls].conf > self.conf_thr and body_kpts[rs].conf > self.conf_thr:
                mid_x = 0.5 * (body_kpts[ls].x + body_kpts[rs].x)

        d_thr = max(img_w, img_h) * 0.2  # ìµœëŒ€ í—ˆìš© ê±°ë¦¬

        for label, score, hand_lm in hands_drawn:
            hlabel = ('Right' if label == 'Left' else 'Left') if MIRROR else label
            w0 = hand_lm.landmark[0]
            hx, hy = int(w0.x * img_w), int(w0.y * img_h)

            best_pt, best_d2 = None, 1e18
            # 1) ë¼ë²¨ ì¼ì¹˜ ìš°ì„ 
            if hlabel in wrists:
                wx, wy = wrists[hlabel]
                d2 = (wx - hx)**2 + (wy - hy)**2
                best_pt, best_d2 = (wx, wy), d2
            # 2) í´ë°±: ë‹¤ë¥¸ìª½
            if best_pt is None and wrists:
                for _, (wx, wy) in wrists.items():
                    d2 = (wx - hx)**2 + (wy - hy)**2
                    if d2 < best_d2:
                        best_pt, best_d2 = (wx, wy), d2
            # 3) ìì—°ìŠ¤ëŸ¬ìš´ ìª½(ì¤‘ì‹¬ì„ ) ìš°ëŒ€
            if best_pt is not None and mid_x is not None and hlabel in wrists:
                natural = 'Left' if hx < mid_x else 'Right'
                if natural in wrists and natural != hlabel:
                    wx2, wy2 = wrists[natural]
                    d2_nat = (wx2 - hx)**2 + (wy2 - hy)**2
                    if d2_nat * 0.8 < best_d2:
                        best_pt, best_d2 = (wx2, wy2), d2_nat
                        hlabel = natural
            # 4) ê±°ë¦¬ ì„ê³„ê°’
            if best_pt is not None and best_d2 <= (d_thr**2):
                cv2.line(img, (hx, hy), best_pt, (255, 255, 255), 2)
                disp = (label if not MIRROR else ('Left' if label == 'Right' else 'Right'))
                cv2.putText(img, f"{disp}", (hx - 30, hy - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                            (0,255,0) if disp == "Left" else (255,0,0), 2)
                
    def overlay_png(img, png, center_x, center_y):
        ph, pw = png.shape[:2]

        # ì¢Œí‘œ ê³„ì‚° (PNGë¥¼ ì¤‘ì‹¬ì— ë†“ëŠ”ë‹¤)
        x1 = int(center_x - pw // 2)
        y1 = int(center_y - ph // 2)
        x2 = x1 + pw
        y2 = y1 + ph

        # í™”ë©´ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡
        h, w = img.shape[:2]
        if x1 < 0 or y1 < 0 or x2 > w or y2 > h:
            return img  # ë²”ìœ„ ë²—ì–´ë‚˜ë©´ ìŠ¤í‚µ

        # PNG split (B,G,R,A)
        b,g,r,a = cv2.split(png)
        overlay = cv2.merge((b,g,r))
        mask = cv2.merge((a,a,a)) / 255.0

        # ì˜¤ë²„ë ˆì´ ì˜ì—­
        roi = img[y1:y2, x1:x2]

        # í•©ì„±
        img[y1:y2, x1:x2] = (roi * (1-mask) + overlay * mask).astype(np.uint8)
        return img


# =========================
# ì† ROI(ì„ íƒ ê¸°ëŠ¥)
# =========================
def get_hand_regions_from_wrist(kpts: Keypoints, img_w: int, img_h: int, size: int = 128) -> List[Tuple[int,int,int,int]]:
    rois = []
    for idx in BODY_WRIST_IDX.values():
        if idx < len(kpts) and kpts[idx].conf > CONF_WRIST:
            x, y = int(kpts[idx].x), int(kpts[idx].y)
            rois.append(clamp_box(x - size//2, y - size//2, x + size//2, y + size//2, img_w, img_h))
    return rois


# =========================
# PNG ì˜¤ë²„ë ˆì´ ì•ˆì „ ë²„ì „ ì´ë¯¸ì§€ ì•„ë˜ìª½ì„ ë¶™ì´ëŠ” ì½”ë“œ
# =========================
def overlay_png_rotate_bottom_center(img, png, p5, p17):
    """
    íšŒì „ ì¤‘ì‹¬: ì›ë³¸ PNGì˜ í•˜ë‹¨ ì¤‘ì•™ (bottom-center)
    p5: ì†ì˜ 5ë²ˆ ì¢Œí‘œì™€ ì´ë¯¸ì§€ì˜ í•˜ë‹¨ ì¤‘ì•™ì„ ì¼ì¹˜
    p17: ë°©í–¥ ê³„ì‚° (5â†’17)
    - íšŒì „ ì‹œ ì´ë¯¸ì§€ê°€ ì˜ë¦¬ì§€ ì•Šë„ë¡ ìº”ë²„ìŠ¤ë¥¼ í™•ì¥
    - íšŒì „ í›„ì—ë„ bottom-centerê°€ ì •í™•íˆ p5ì— ë§ê²Œ ìœ ì§€
    """
    ph0, pw0 = png.shape[:2]

    # ===== ë°©í–¥ ë²¡í„° ë° ê°ë„ ê³„ì‚° =====
    dx, dy = p17[0] - p5[0], p17[1] - p5[1]
    angle = math.degrees(math.atan2(dy, dx))
    rot_deg = -(angle - 90)

    # ===== ì±„ë„ ë¶„ë¦¬ =====
    if png.shape[2] == 4:
        b, g, r, a = cv2.split(png)
        rgb = cv2.merge((b, g, r))
    else:
        rgb = png
        a = np.full((ph0, pw0), 255, np.uint8)

    # ===== ìº”ë²„ìŠ¤ í™•ì¥ (ì˜ë¦¼ ë°©ì§€ìš© ì—¬ë°± ì¶”ê°€) =====
    margin = max(ph0, pw0)
    pad = cv2.copyMakeBorder(png, margin, margin, margin, margin, cv2.BORDER_CONSTANT, value=[0, 0, 0, 0])
    ph, pw = pad.shape[:2]

    # ===== ìƒˆ ì•µì»¤ (í™•ì¥ëœ í•˜ë‹¨ ì¤‘ì•™) =====
    anchor = (pw / 2, ph - margin)

    # ===== íšŒì „ í›„ bounding box í¬ê¸° ê³„ì‚° =====
    rad = math.radians(rot_deg)
    c, s = abs(math.cos(rad)), abs(math.sin(rad))
    new_w = int(pw * c + ph * s)
    new_h = int(pw * s + ph * c)

    # ===== íšŒì „ í–‰ë ¬ + ì¤‘ì‹¬ ë³´ì • =====
    M = cv2.getRotationMatrix2D(anchor, rot_deg, 1.0)
    M[0, 2] += (new_w / 2) - anchor[0]
    M[1, 2] += (new_h / 2) - anchor[1]

    # ===== íšŒì „ ìˆ˜í–‰ =====
    rotated = cv2.warpAffine(pad, M, (new_w, new_h),
                             flags=cv2.INTER_AREA,
                             borderMode=cv2.BORDER_CONSTANT,
                             borderValue=(0, 0, 0, 0))

    # ===== íšŒì „ í›„ ì•µì»¤ ì¢Œí‘œ ê³„ì‚° (ì§„ì§œ í•˜ë‹¨ ì¤‘ì•™ì ì´ ì–´ë”” ìˆëŠ”ì§€) =====
    ax = M[0, 0] * anchor[0] + M[0, 1] * anchor[1] + M[0, 2]
    ay = M[1, 0] * anchor[0] + M[1, 1] * anchor[1] + M[1, 2]

    # ===== p5ì™€ (ax, ay)ë¥¼ ì¼ì¹˜ì‹œì¼œ ì˜¤ë²„ë ˆì´ =====
    x1 = int(p5[0] - ax)
    y1 = int(p5[1] - ay)
    x2, y2 = x1 + new_w, y1 + new_h

    # ===== í™”ë©´ í´ë¨í”„ =====
    H, W = img.shape[:2]
    if x2 <= 0 or y2 <= 0 or x1 >= W or y1 >= H:
        return img

    x1c, y1c = max(0, x1), max(0, y1)
    x2c, y2c = min(W, x2), min(H, y2)
    png_crop = rotated[(y1c - y1):(y2c - y1), (x1c - x1):(x2c - x1)]
    roi = img[y1c:y2c, x1c:x2c]

    # ===== ì•ŒíŒŒ í•©ì„± =====
    if png_crop.shape[2] == 4:
        b, g, r, a = cv2.split(png_crop)
        overlay = cv2.merge((b, g, r))
        mask = cv2.merge((a, a, a)) / 255.0
    else:
        overlay = png_crop
        mask = np.ones_like(overlay, dtype=np.float32)

    img[y1c:y2c, x1c:x2c] = (roi * (1 - mask) + overlay * mask).astype(np.uint8)
    return img






# =========================
# ë©”ì¸
# =========================
def main():
    pose = OpenVinoPose(MODEL_XML, DEVICE)
    hands = MediaPipeHands(MAX_HANDS)

    # ===============================
    # 53ì¥ì˜ PNG í”„ë ˆì„ ë¡œë“œ
    # ===============================
    import glob
    frame_files = sorted(glob.glob("datasets/LightsaberPNG/ezgif-frame-*.png"))
    if not frame_files:
        raise FileNotFoundError("âš ï¸ PNG í”„ë ˆì„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print(f"ğŸ”¹ {len(frame_files)}ê°œì˜ PNG í”„ë ˆì„ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

    overlay_frames = []
    for f in frame_files:
        img = cv2.imread(f, cv2.IMREAD_UNCHANGED)
        if img is None:
            continue
        img = make_black_transparent(img, thr=30, soft_edge=5)
        overlay_frames.append(img)

    total_frames = len(overlay_frames)
    frame_idx = 0
    scale = 0.45
    SCALE_STEP = 0.1
    MIN_SCALE, MAX_SCALE = 0.25, 3.0

    cap = cv2.VideoCapture(CAM_INDEX)
    prev_t = 0.0

    while cap.isOpened():
        ok, frame = cap.read()
        if not ok:
            break
        h, w = frame.shape[:2]

        # ============= ì „ì‹  í¬ì¦ˆ ì¶”ë¡  =============
        out = pose.infer(frame)
        body_kpts = pose.extract_keypoints(out, w, h)
        viz = Visualizer()
        viz.draw_skeleton(frame, body_kpts, (0, 255, 0))

        # ============= ì† ì¶”ì • (MediaPipe) =========
        results = hands.process(frame)
        hands_drawn = hands.draw(frame, results)

        # MIRROR ê³ ë ¤í•œ ì˜¤ë¥¸ì† íŒë³„
        right_hand_kpts = None
        for label, score, hand_lm in hands_drawn:
            is_right = (label == "Right") if not MIRROR else (label == "Left")
            if is_right:
                right_hand_kpts = [Keypoint(lm.x * w, lm.y * h, 1.0) for lm in hand_lm.landmark]
                break

        # ==============================
        # ë¼ì´íŠ¸ì„¸ì´ë²„ ì˜¤ë²„ë ˆì´ ì²˜ë¦¬
        # ==============================
        if right_hand_kpts and len(right_hand_kpts) > 17:
            # ---- ì†ì˜ ì£¼ìš” ì  ----
            p5 = (int(right_hand_kpts[5].x), int(right_hand_kpts[5].y))
            p17 = (int(right_hand_kpts[17].x), int(right_hand_kpts[17].y))

            # ---- ì§ì„  ì‹œê°í™” ----
            cv2.line(frame, p5, p17, (0, 255, 255), 2)
            cv2.circle(frame, p5, 5, (0, 0, 255), -1)  # 5ë²ˆ (ë¹¨ê°•)
            cv2.circle(frame, p17, 5, (255, 0, 0), -1) # 17ë²ˆ (íŒŒë‘)

            # ---- ë°©í–¥ ë²¡í„° (5â†’17)
            dx, dy = p17[0] - p5[0], p17[1] - p5[1]
            length = math.hypot(dx, dy)
            if length == 0:
                length = 1
            dir_x, dir_y = dx / length, dy / length

            # ---- ì—¬ê¸°ì„œ offset ì œê±°
            # ë‹¨ì§€ ë°˜ëŒ€ ë°©í–¥ì˜ ì—°ì¥ì„ ë§Œ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ
            line_len = 200
            end_x = int(p5[0] - dir_x * line_len)
            end_y = int(p5[1] - dir_y * line_len)
            cv2.line(frame, p5, (end_x, end_y), (0, 255, 0), 2)  # ì—°ì¥ì„  í‘œì‹œ

            # ---- ìŠ¤ì¼€ì¼ ì¡°ì • ----
            base = overlay_frames[frame_idx]
            if scale != 1.0:
                new_w = max(1, int(base.shape[1] * scale))
                new_h = max(1, int(base.shape[0] * scale))
                overlay_img = cv2.resize(base, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            else:
                overlay_img = base

            # ---- ì˜¤ë²„ë ˆì´ (í•˜ë‹¨ ì¤‘ì•™ì´ p5) ----
            frame = overlay_png_rotate_bottom_center(frame, overlay_img, p5, p17)



            # ---- ë””ë²„ê·¸ í‘œì‹œ ----
            cv2.putText(frame, "bottom_center=p5", (p5[0] + 10, p5[1] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
            frame_idx = (frame_idx + 1) % total_frames

        # ============= FPS í‘œì‹œ =============
        now = time.time()
        fps = 1.0 / (now - prev_t) if prev_t else 0.0
        prev_t = now
        cv2.putText(frame, f"FPS: {int(fps)}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        # ============= ì¶œë ¥ =============
        cv2.imshow("Full Body + Hand Pose + Lightsaber Animation", frame)
        key = cv2.waitKey(1) & 0xFF
        if key == 27:  # ESC ì¢…ë£Œ
            break
        elif key in (ord('-'), ord('_')):  # ğŸ”» ì¶•ì†Œ
            scale = max(MIN_SCALE, round(scale - SCALE_STEP, 2))
            print(f"ğŸ”» ì´ë¯¸ì§€ ì¶•ì†Œ: scale={scale}")
        elif key in (ord('='), ord('+')):  # ğŸ”º í™•ëŒ€
            scale = min(MAX_SCALE, round(scale + SCALE_STEP, 2))
            print(f"ğŸ”º ì´ë¯¸ì§€ í™•ëŒ€: scale={scale}")

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
